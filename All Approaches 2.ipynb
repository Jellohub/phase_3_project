{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "660be687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, get_scorer_names, confusion_matrix, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from statistics import mode as md\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output, display_html \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4a93e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f83abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv(\"tanzanian_water_wells/X_test.csv\")\n",
    "X = pd.read_csv(\"tanzanian_water_wells/X_train.csv\")\n",
    "y = pd.read_csv(\"tanzanian_water_wells/y_train.csv\")['status_group'].map({'functional': 2, 'functional needs repair': 0, 'non functional': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ccfd6ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dropping unecessary columns\n",
    "X = X.drop(['id', 'wpt_name', 'subvillage', 'installer', 'funder', 'scheme_name', 'ward', 'date_recorded', 'recorded_by'], axis=1)\n",
    "testing = testing.drop(['id', 'wpt_name', 'subvillage', 'installer', 'funder', 'scheme_name', 'ward', 'date_recorded', 'recorded_by'], axis=1)\n",
    "\n",
    "# Eliminating null values from X_train\n",
    "X.scheme_management.fillna(\"None\", inplace=True)\n",
    "X.permit.fillna('Unknown', inplace=True)\n",
    "X.public_meeting.fillna('Unknown', inplace=True)\n",
    "\n",
    "# Turning certain dtypes into others\n",
    "X['permit'] = X['permit'].map({True: 'Yes', False: 'No', 'Unknown': 'Unknown'})\n",
    "X['gps_height'] = X['gps_height'].astype('float64')\n",
    "X['population'] = X['population'].astype('float64')\n",
    "X['construction_year'] = X['construction_year'].astype('int64')\n",
    "X['region_code'] = X['region_code'].astype('str')\n",
    "X['district_code'] = X['district_code'].astype('str')\n",
    "\n",
    "#Defining X_cat\n",
    "X_cat = X.select_dtypes(exclude=['float64', 'int64'])\n",
    "X_cat = X_cat.astype('str')\n",
    "X_cat = pd.get_dummies(X_cat)\n",
    "\n",
    "#Defining X_numeric\n",
    "X_numeric = X.select_dtypes(['float64', 'int64'])\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_numeric)\n",
    "X_numeric = pd.DataFrame(scaler.transform(X_numeric), columns = X_numeric.columns, index = X_numeric.index)\n",
    "\n",
    "#Defining X\n",
    "X = pd.concat([X_numeric, X_cat], axis=1)\n",
    "\n",
    "#Defining df\n",
    "df = pd.concat([X, y], axis=1)\n",
    "\n",
    "#Creating a train-test-split for X and y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#Resampling dataframes for model creation\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "X_train_resampled = X_train_resampled.reset_index(drop=True)\n",
    "y_train_resampled = y_train_resampled.reset_index(drop=True)\n",
    "    \n",
    "df_resampled = pd.concat([X_train_resampled, y_train_resampled], axis=1)\n",
    "\n",
    "#Separating concatenated dataframe into each status group\n",
    "f = df_resampled[df_resampled.status_group == 0].reset_index(drop=True).copy()\n",
    "nf = df_resampled[df_resampled.status_group == 2].reset_index(drop=True).copy()\n",
    "fnr = df_resampled[df_resampled.status_group == 1].reset_index(drop=True).copy()\n",
    "\n",
    "#Shuffling all the records\n",
    "f = f.sample(frac=1)\n",
    "nf = nf.sample(frac=1)\n",
    "fnr = fnr.sample(frac=1)\n",
    "\n",
    "#Splitting each status group into arrays of approximately 1,000 records\n",
    "fs = [pd.DataFrame(i) for i in np.array_split(f, len(f)//1000)]\n",
    "nfs = [pd.DataFrame(i) for i in np.array_split(nf, len(nf)//1000)]\n",
    "fnrs = [pd.DataFrame(i) for i in np.array_split(fnr, len(fnr)//1000)]\n",
    "\n",
    "#Creating our individual samples for models to train on\n",
    "resamples = []\n",
    "for i in range(len(fnrs)):\n",
    "    resample = pd.concat([fs[i], nfs[i], fnrs[i]])\n",
    "    resamples.append(resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e008916e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m estimators \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m'\u001b[39m: LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \n\u001b[1;32m      2\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecision Tree Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: DecisionTreeClassifier(), \n\u001b[1;32m      3\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK-Nearest Neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), \n\u001b[1;32m      4\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBagging Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: BaggingClassifier(estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m), \n\u001b[1;32m      5\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m'\u001b[39m: RandomForestClassifier(), \n\u001b[1;32m      6\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXG-Boost\u001b[39m\u001b[38;5;124m'\u001b[39m: XGBClassifier(), \n\u001b[1;32m      7\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdaboost\u001b[39m\u001b[38;5;124m'\u001b[39m: AdaBoostClassifier(estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \n\u001b[1;32m      8\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGradient Boosted Trees\u001b[39m\u001b[38;5;124m'\u001b[39m: GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m), \n\u001b[1;32m      9\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtra Randomized Trees\u001b[39m\u001b[38;5;124m'\u001b[39m: ExtraTreesClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \n\u001b[1;32m     10\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStacking Classifier\u001b[39m\u001b[38;5;124m'\u001b[39m: StackingClassifier(\n\u001b[1;32m     11\u001b[0m         estimators \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)), \n\u001b[1;32m     12\u001b[0m                       (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbagging_classifier\u001b[39m\u001b[38;5;124m'\u001b[39m, BaggingClassifier(estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(), n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m))], \n\u001b[1;32m     13\u001b[0m         final_estimator \u001b[38;5;241m=\u001b[39m XGBClassifier())}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "estimators = {'Logistic Regression': LogisticRegression(solver='liblinear', fit_intercept=False), \n",
    "              'Decision Tree Classifier': DecisionTreeClassifier(), \n",
    "              'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=3), \n",
    "              'Bagging Classifier': BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, max_features=50), \n",
    "              'Random Forest': RandomForestClassifier(), \n",
    "              'XG-Boost': XGBClassifier(), \n",
    "              'Adaboost': AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42), \n",
    "              'Gradient Boosted Trees': GradientBoostingClassifier(random_state=42, n_estimators=200, max_features=50), \n",
    "              'Extra Randomized Trees': ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b96539",
   "metadata": {},
   "source": [
    "# Approach #1 – Single Model with Original Data\n",
    "\n",
    "Here we use a single estimator on a training dataset and make predictions on a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b576771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator Logistic Regression completed.\n",
      "Estimator Decision Tree Classifier completed.\n",
      "Estimator K-Nearest Neighbors completed.\n",
      "Estimator Bagging Classifier completed.\n",
      "Estimator Random Forest completed.\n",
      "Estimator XG-Boost completed.\n",
      "Estimator Adaboost completed.\n",
      "Estimator Gradient Boosted Trees completed.\n",
      "Estimator Extra Randomized Trees completed.\n",
      "Estimator Stacking Classifier completed.\n"
     ]
    }
   ],
   "source": [
    "ap1_dict = {}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, predictions))\n",
    "    report = pd.DataFrame(classification_report(y_test, predictions, output_dict=True))\n",
    "    ap1_dict[name] = [predictions, matrix, report]\n",
    "    \n",
    "    print(f\"Estimator {name} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401858ea",
   "metadata": {},
   "source": [
    "# Approach #2 – Single Model with Resampled Data\n",
    "\n",
    "Here we use a single estimator on a resampled training dataset and make predictions on a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "996d93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa9d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator Logistic Regression completed.\n",
      "Estimator Decision Tree Classifier completed.\n",
      "Estimator K-Nearest Neighbors completed.\n",
      "Estimator Bagging Classifier completed.\n",
      "Estimator Random Forest completed.\n",
      "Estimator XG-Boost completed.\n",
      "Estimator Adaboost completed.\n",
      "Estimator Gradient Boosted Trees completed.\n",
      "Estimator Extra Randomized Trees completed.\n",
      "Estimator Stacking Classifier completed.\n"
     ]
    }
   ],
   "source": [
    "ap2_dict = {}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    \n",
    "    estimator.fit(X_train_resampled, y_train_resampled)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, predictions))\n",
    "    report = pd.DataFrame(classification_report(y_test, predictions, output_dict=True))\n",
    "    ap2_dict[name] = [predictions, matrix, report]\n",
    "    \n",
    "    print(f\"Estimator {name} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc54e6",
   "metadata": {},
   "source": [
    "# Approach #3 – Single Model with Resampled Data (Different Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e74d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {0: 10000} #optional strategy\n",
    "smote = SMOTE(sampling_strategy=strategy)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4ca9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator Logistic Regression completed.\n",
      "Estimator Decision Tree Classifier completed.\n",
      "Estimator K-Nearest Neighbors completed.\n",
      "Estimator Bagging Classifier completed.\n",
      "Estimator Random Forest completed.\n",
      "Estimator XG-Boost completed.\n",
      "Estimator Adaboost completed.\n",
      "Estimator Gradient Boosted Trees completed.\n",
      "Estimator Extra Randomized Trees completed.\n",
      "Estimator Stacking Classifier completed.\n"
     ]
    }
   ],
   "source": [
    "ap3_dict = {}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    \n",
    "    estimator.fit(X_train_resampled, y_train_resampled)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, predictions))\n",
    "    report = pd.DataFrame(classification_report(y_test, predictions, output_dict=True))\n",
    "    ap3_dict[name] = [predictions, matrix, report]\n",
    "    \n",
    "    print(f\"Estimator {name} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207233b",
   "metadata": {},
   "source": [
    "# Approach #4 – Single Model with Resampled Data (Different Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e862183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {0: 15000} #optional strategy\n",
    "smote = SMOTE(sampling_strategy=strategy)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e921b720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator Logistic Regression completed.\n",
      "Estimator Decision Tree Classifier completed.\n",
      "Estimator K-Nearest Neighbors completed.\n",
      "Estimator Bagging Classifier completed.\n",
      "Estimator Random Forest completed.\n",
      "Estimator XG-Boost completed.\n",
      "Estimator Adaboost completed.\n",
      "Estimator Gradient Boosted Trees completed.\n",
      "Estimator Extra Randomized Trees completed.\n",
      "Estimator Stacking Classifier completed.\n"
     ]
    }
   ],
   "source": [
    "ap4_dict = {}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    \n",
    "    estimator.fit(X_train_resampled, y_train_resampled)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, predictions))\n",
    "    report = pd.DataFrame(classification_report(y_test, predictions, output_dict=True))\n",
    "    ap4_dict[name] = [predictions, matrix, report]\n",
    "    \n",
    "    print(f\"Estimator {name} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98d444",
   "metadata": {},
   "source": [
    "# Approach #5 – Single Model with Resampled Data (Different Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5448674",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = {0: 20000} #optional strategy\n",
    "smote = SMOTE(sampling_strategy=strategy)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e27db205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator Logistic Regression completed.\n",
      "Estimator Decision Tree Classifier completed.\n",
      "Estimator K-Nearest Neighbors completed.\n",
      "Estimator Bagging Classifier completed.\n",
      "Estimator Random Forest completed.\n",
      "Estimator XG-Boost completed.\n",
      "Estimator Adaboost completed.\n",
      "Estimator Gradient Boosted Trees completed.\n",
      "Estimator Extra Randomized Trees completed.\n",
      "Estimator Stacking Classifier completed.\n"
     ]
    }
   ],
   "source": [
    "ap5_dict = {}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    \n",
    "    estimator.fit(X_train_resampled, y_train_resampled)\n",
    "    predictions = estimator.predict(X_test)\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, predictions))\n",
    "    report = pd.DataFrame(classification_report(y_test, predictions, output_dict=True))\n",
    "    ap5_dict[name] = [predictions, matrix, report]\n",
    "    \n",
    "    print(f\"Estimator {name} completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d5f91",
   "metadata": {},
   "source": [
    "# Approach #6 – Voting Classifiers on Different Data Samples\n",
    "\n",
    "After resampling the data, we split it into multiple samples with equal amounts of each status group. An estimator is trained on each sample and makes different predictions for that dataset based on each sample. A mock voting classifier is made from the resulting model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67fc1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ap6_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76dcb4f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: #23\n",
      "Estimator: Stacking Classifier\n"
     ]
    }
   ],
   "source": [
    "for name, est in estimators.items():\n",
    "\n",
    "    preds = []\n",
    "    modes=[]\n",
    "    counters=[]\n",
    "    \n",
    "    for i in range(len(resamples)):\n",
    "        estimator =  est\n",
    "        X = resamples[i].drop(['status_group'], axis=1)\n",
    "        y = resamples[i]['status_group']\n",
    "        estimator.fit(X, y)\n",
    "        pred = estimator.predict(X_test)\n",
    "        preds.append(pred)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Sample: #{i}\")\n",
    "        print(f\"Estimator: {name}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "\n",
    "    for i in range(len(preds[0])):\n",
    "        counter = Counter([pred[i] for pred in preds])\n",
    "        counters.append(counter)\n",
    "\n",
    "    counter_modes = []\n",
    "    for counter in counters:\n",
    "        counter_mode = sorted(counter.items(), key=lambda x: [x[1], x[0]], reverse=True)[0][0]\n",
    "        counter_modes.append(counter_mode)\n",
    "\n",
    "    matrix = pd.DataFrame(confusion_matrix(y_test, counter_modes))\n",
    "    report = pd.DataFrame(classification_report(y_test, counter_modes, output_dict=True))\n",
    "    \n",
    "    ap6_dict[name] = [preds, counter_modes, matrix, report]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac2b59",
   "metadata": {},
   "source": [
    "# Looking at All of our Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af60f4da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimators' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m master_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m estimators\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      3\u001b[0m     ap1 \u001b[38;5;241m=\u001b[39m ap1_dict[name][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m     ap2 \u001b[38;5;241m=\u001b[39m ap2_dict[name][\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimators' is not defined"
     ]
    }
   ],
   "source": [
    "master_dict = {}\n",
    "for name in estimators.keys():\n",
    "    ap1 = ap1_dict[name][2]\n",
    "    ap2 = ap2_dict[name][2]\n",
    "    ap3 = ap3_dict[name][2]\n",
    "    ap4 = ap4_dict[name][2]\n",
    "    ap5 = ap5_dict[name][2]\n",
    "#     ap6 = ap6_dict[name][3]\n",
    "    master_dict[name]=[ap1,ap2,ap3,ap4,ap5]\n",
    "    \n",
    "print(\"\\n\")\n",
    "for name, results in master_dict.items():\n",
    "    print(color.BOLD + name + color.END)\n",
    "    display(results[0].style.set_caption(\"original data\"))\n",
    "    display(results[1].style.set_caption(\"resampled data\"))\n",
    "    display(results[2].style.set_caption(\"resampled data (n = 10000)\"))\n",
    "    display(results[3].style.set_caption(\"resampled data (n = 15000)\"))\n",
    "    display(results[4].style.set_caption(\"resampled data (n = 20000)\"))\n",
    "#     display(results[5].style.set_caption(\"resampled samples\"))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154dc1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
